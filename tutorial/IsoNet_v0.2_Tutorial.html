<!DOCTYPE html>
<html>
<head>
<title>IsoNet_v0.2_Tutorial.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>
<link rel="stylesheet" href="file:///home/cii/software/IsoNet/.vscode/github-markdown.css" type="text/css">
<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>
<link rel="stylesheet" href="file:///home/cii/software/IsoNet/.vscode/github-markdown.css" type="text/css">
<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="isonet-tutorial">IsoNet Tutorial</h1>
<p>The publication associated with IsoNet can be found here: https://www.biorxiv.org/content/10.1101/2021.07.17.452128v1</p>
<h2 id="table-of-contents">Table of contents</h2>
<ol>
<li><a href="#1-introduction">Introduction</a></li>
<li><a href="#2-examples">Examples</a>
<ul>
<li><a href="#21-isonet-for-virus-tomograms">2.1 IsoNet for virus tomograms</a>
<ul>
<li><a href="#211-prepare-tomograms-and-star-file">2.1.1 Prepare tomograms and STAR file</a></li>
<li><a href="#212-ctf-deconvolve">2.1.2 CTF Deconvolve</a></li>
<li><a href="#213-generate-mask">2.1.3 Generate Mask</a></li>
<li><a href="#214-extract-subtomograms">2.1.4 Extract Subtomograms</a></li>
<li><a href="#215-refine">2.1.5 Refine</a></li>
<li><a href="#216-predict">2.1.6 Predict</a></li>
</ul>
</li>
<li><a href="#22-isonet-for-cellular-tomography">2.2 IsoNet for cellular tomography</a>
<ul>
<li><a href="#221-run-isonet-from-command-line">2.2.1 Run IsoNet from command line</a></li>
<li><a href="#222-run-isonet-with-gui">2.2.2 Run IsoNet with GUI</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3-individual-tasks">Individual tasks</a>
<ul>
<li><a href="#31-prepare-tomograms-and-star-file">3.1 Prepare tomograms and STAR file</a></li>
<li><a href="#32-ctf-deconvolve">3.2 CTF deconvolve</a></li>
<li><a href="#33-generate-mask">3.3 Generate mask</a>
<ul>
<li><a href="#331-pixel-intensity-mask">3.3.1 Pixel intensity mask</a></li>
<li><a href="#332-standard-deviation-mask">3.3.2 Standard deviation mask</a></li>
<li><a href="#333-draw-a-polygon-to-define-area-of-interest">3.3.3 Draw a polygon to define area of interest</a></li>
</ul>
</li>
<li><a href="#34-extract">3.4 Extract</a>
<ul>
<li><a href="#341-extract-from-tomograms">3.4.1 Extract from tomograms</a></li>
<li><a href="#342-prepare-star-file-from-subtomograms">3.4.2 Prepare star file from subtomograms</a></li>
</ul>
</li>
<li><a href="#35-refine">3.5 Refine</a>
<ul>
<li><a href="#351-computation-resources">3.5.1 Computation resources</a></li>
<li><a href="#352-optimizing-training-speed">3.5.2 Optimizing training speed</a></li>
<li><a href="#353-denoising">3.5.3 Denoising</a></li>
<li><a href="#354-network-structure">3.5.4 Network structure</a></li>
<li><a href="#355-continuing-using-the-previously-trained-network">3.5.5 Continuing using the previously trained network</a></li>
</ul>
</li>
<li><a href="#36-predict">3.6 Predict</a></li>
</ul>
</li>
<li><a href="#4-gui">Graphic user interface</a></li>
</ol>
<div style="page-break-after: always;"></div>
<h2 id="1-introduction">1 Introduction</h2>
<p><strong>IsoNet</strong> stands for for ISOtropic reconstructioN of Electron Tomography. It trains deep neural networks to reconstruct meaningful contents in the missing wedge for electron tomography increase signal-to-noise ratio using the information learned from the original tomogram. The software requires tomograms as input. Observing at about 30A resolution, the IsoNet generated tomograms are largely isotropic.</p>
<p><strong>IsoNet</strong> contains modules: prepare star, CTF deconvolve, generate mask, extract, refine and predict. All commands in IsoNet operate on <strong>.star</strong> text files which include description and path of data and parameters for tasks mentioned above. For detailed descriptions of each module please refer to the individual tasks. Users can choose to utilize IsoNet through either GUI or command-lines.</p>
<p>In version <strong>0.2</strong>, user can <a href="#33-draw-a-polygon-to-define-area-of-interest">draw polygons</a> to define the region of mask. This option would be useful to exclude carbon areas.</p>
<h2 id="2-examples">2 Examples</h2>
<p>The following two exmaples describe the basic steps of running the program and generating missing wedge corrected tomograms using both command line and GUI. <strong>The dataset and a video tutorial can be found <a href="https://drive.google.com/drive/folders/1DXjIsz6-EiQm7mBMuMHHwdZErZ_bXAgp">here</a>.</strong></p>
<h3 id="21-isonet-for-virus-tomograms">2.1 IsoNet for virus tomograms</h3>
<p>The dataset used in this tutorial contains 8-times binned tomograms reconstructed from three tilt series in EMPIAR-10164.</p>
<p align="center"><img src="figures/fig1.png" width="700" /> </p>
<h4 id="211-prepare-tomograms-and-star-file">2.1.1 Prepare tomograms and STAR file</h4>
<p>First, create a folder for your project. In this folder, create
subfolder (in this case subfolder name is tomoset) and move all tomogram
(with suffix .mrc or .rec) to the subfolder.</p>
<pre class="hljs"><code><div>mkdir tomoset
mv TS*.rec tomoset/
</div></code></pre>
<p>Then run the following command in your project folder to generate a
tomogram.star file (in this example, the name of tomogram.star file is
hiv_tomo.star)</p>
<pre class="hljs"><code><div>isonet.py prepare_star tomoset --output_star hiv_tomo.star --pixel_size 10.8
</div></code></pre>
<p>If you are not using GUI, please use your favorite text editor, such as
vi or gedit, to open the <strong>hiv_tomo.star</strong>, and enter one defocus value
for each tomogram in the fourth column. This value should be the approximate
defocus value calculated for the 0-degree tilt images in angstrom. After
editing, your star file should look as follows. Note, this value is
only for CTF deconvolution, if you want to skip CTF deconvolution step,
leave this column as default 0.</p>
<pre class="hljs"><code><div>data_

loop_
_rlnIndex #1
_rlnMicrographName #2
_rlnPixelSize #3
_rlnDefocus #4
_rlnNumberSubtomo #5
1       tomoset/TS01-wbp.rec    10.800000       38838.257812    100
2       tomoset/TS43-wbp.rec    10.800000       25292.275391    100
3       tomoset/TS45-wbp.rec    10.800000       30169.785156    100
</div></code></pre>
<h4 id="212-ctf-deconvolve">2.1.2 CTF Deconvolve</h4>
<p>This step not only reduces the CTF artifact but also enhances the low
resolution signal making training easier. This step is optional and can
not be performed for tomograms acquired with phase plate.</p>
<p>Type the following command in the terminal in your project folder. It
will generate deconvolved tomograms in <strong>hiv_deconv</strong> folder.</p>
<pre class="hljs"><code><div>isonet.py deconv hiv_tomo.star --snrfalloff 0.7 --deconv_folder hiv_deconv
</div></code></pre>
<p>If the command runs successfully, you will get the following terminal
output:</p>
<pre class="hljs"><code><div>######Isonet starts ctf deconvolve######

tomoset/TS01-wbp.rec angpix: 10.8 defocus 3.8838257812 snrfalloff 0.7 deconvstrength 1.0
deconvolved map is saved as  hiv_deconv/TS01-wbp.rec
time consumed:  14.191490888595581

tomoset/TS43-wbp.rec angpix: 10.8 defocus 2.5292275391 snrfalloff 0.7 deconvstrength 1.0
deconvolved map is saved as  hiv_deconv/TS01-wbp.rec
time consumed:  8.547893047332764

tomoset/TS45-wbp.rec angpix: 10.8 defocus 3.0169785156 snrfalloff 0.7 deconvstrength 1.0
deconvolved map is saved as  hiv_deconv/TS01-wbp.rec
time consumed:  8.76533579826355

######Isonet done ctf deconvolve######
</div></code></pre>
<h4 id="213-generate-mask">2.1.3 Generate Mask</h4>
<p>To exclude the areas that are devoid of sample, we apply a binary sampling
mask to each tomogram. This step is optional but will improve the
efficiency of the network training.</p>
<p>By running the following command, 3D mask volumes for each tomogram will be
generated and stored in the <strong>hiv_mask</strong> folder. Default parameters will
give you a good enough mask.</p>
<pre class="hljs"><code><div>isonet.py make_mask hiv_tomo.star --mask_folder hiv_mask --density_percentage 50 --std_percentage 50
</div></code></pre>
<p>If this command works properly, you will find the mask file, when opened
with your favorite mrc image viewer such as 3dmod, covers the areas of
your sample of interest. Both this step and CTF deconvolve step will
modify your tomogram star file (<strong>hiv_tomo.star</strong>):</p>
<pre class="hljs"><code><div>data_

loop_
_rlnIndex #1
_rlnMicrographName #2
_rlnPixelSize #3
_rlnDefocus #4
_rlnNumberSubtomo #5
_rlnSnrFalloff #6
_rlnDeconvStrength #7
_rlnDeconvTomoName #8
_rlnMaskDensityPercentage #9
_rlnMaskStdPercentage #10
_rlnMaskName #11
1       tomoset/TS01-wbp.rec    10.800000       38838.257812    100     0.700000        1.000000        hiv_deconv/TS01-wbp.rec         50.000000    50.000000       hiv_mask/TS01-wbp_mask.mrc
2       tomoset/TS43-wbp.rec    10.800000       25292.275391    100     0.700000        1.000000        hiv_deconv/TS43-wbp.rec         50.000000    50.000000       hiv_mask/TS43-wbp_mask.mrc
3       tomoset/TS45-wbp.rec    10.800000       30169.785156    100     0.700000        1.000000        hiv_deconv/TS45-wbp.rec         50.000000    50.000000       hiv_mask/TS45-wbp_mask.mrc
</div></code></pre>
<h4 id="214-extract-subtomograms">2.1.4 Extract Subtomograms</h4>
<p>This step extracts small 3D volumes (here we also call subtomograms)
randomly from previously described tomograms or deconvoluted tomograms. If
you provide a mask in your tomogram star file, the center of the
subtomograms is inside the mask areas. The number of subtomograms to be
extracted in each tomogram is defined in the <strong>_rlnNumberSubtomo</strong>
column in your tomogram star file. You can edit those as your desired
value. Usually, total of 300 subtomograms are sufficient for network
training.</p>
<p>The following command takes your tomogram star file as input and
Generates subtomograms in a folder named subtomo as well as a file named
subtomo.star</p>
<pre class="hljs"><code><div>isonet.py extract hiv_tomo.star
</div></code></pre>
<p>The subtomo.star contains information for your subtomograms.
<strong>_rlnCropSize</strong> is the size of subtomograms, and <strong>_rlnCubeSize</strong> is the
size actually used for network training, You can specify these values in
the <em>extract</em> command.</p>
<pre><code>data_

loop_
_rlnSubtomoIndex #1
_rlnImageName #2
_rlnCubeSize #3
_rlnCropSize #4
_rlnPixelSize #5
1       subtomo/TS01-wbp_000000.mrc     64      96      10.800000
2       subtomo/TS01-wbp_000001.mrc     64      96      10.800000
3       subtomo/TS01-wbp_000002.mrc     64      96      10.800000
4       subtomo/TS01-wbp_000003.mrc     64      96      10.800000
5       subtomo/TS01-wbp_000004.mrc     64      96      10.800000
6       subtomo/TS01-wbp_000005.mrc     64      96      10.800000
7       subtomo/TS01-wbp_000006.mrc     64      96      10.800000
8       subtomo/TS01-wbp_000007.mrc     64      96      10.800000
9       subtomo/TS01-wbp_000008.mrc     64      96      10.800000
10      subtomo/TS01-wbp_000009.mrc     64      96      10.800000
11      subtomo/TS01-wbp_000010.mrc     64      96      10.800000
12      subtomo/TS01-wbp_000011.mrc     64      96      10.800000
</code></pre>
<h4 id="215-refine">2.1.5 Refine</h4>
<p>The extracted sub-tomograms and subtomo star file are used as input in
this refine step, which iteratively trains networks that fill the
missing wedge information (and reduce noise). The output is defined by
<strong>the result_dir</strong> parameter, whose default value is &quot;results&quot;. In this
folder, you will find all the subtomograms in each iteration as well as
the network model files with the extension of h5, if this command runs
successfully.</p>
<p>it will take about 10 hours for four Nvidia 1080Ti to finish the refine
step with the following command:</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --gpuID 0,1,2,3 --iterations 30 --noise_start_iter 10,15,20,25 --noise_level 0.05,0.1,0.15,0.2 
</div></code></pre>
<p>Once you execute the refine step, you will get the command line output
as follows:</p>
<pre class="hljs"><code><div>######Isonet starts refining######

06-11 22:00:55, INFO     Done preperation for the first iteration!
06-11 22:00:55, INFO     Start Iteration1!
06-11 22:00:59, INFO     Noise Level:0.0
06-11 22:01:36, INFO     Done preparing subtomograms!
06-11 22:01:36, INFO     Start training!
06-11 22:01:38, INFO     Loaded model from disk
06-11 22:01:38, INFO     begin fitting
Epoch 1/10
112/112 [==============================] - 106s 944ms/step - loss: 0.1597 - mse: 0.0726 - mae: 0.1597 - val_loss: 0.1575 - val_mse: 0.0711 - val_mae: 0.1575
Epoch 2/10
112/112 [==============================] - 101s 897ms/step - loss: 0.1543 - mse: 0.0591 - mae: 0.1543 - val_loss: 0.1617 - val_mse: 0.0726 - val_mae: 0.1617
Epoch 3/10
112/112 [==============================] - 101s 904ms/step - loss: 0.1489 - mse: 0.0513 - mae: 0.1489 - val_loss: 0.1535 - val_mse: 0.0616 - val_mae: 0.1535
Epoch 4/10
112/112 [==============================] - 101s 903ms/step - loss: 0.1486 - mse: 0.0489 - mae: 0.1486 - val_loss: 0.1583 - val_mse: 0.0687 - val_mae: 0.1583
Epoch 5/10
112/112 [==============================] - 101s 905ms/step - loss: 0.1467 - mse: 0.0458 - mae: 0.1467 - val_loss: 0.1482 - val_mse: 0.0478 - val_mae: 0.1482
Epoch 6/10
112/112 [==============================] - 102s 906ms/step - loss: 0.1449 - mse: 0.0442 - mae: 0.1449 - val_loss: 0.1472 - val_mse: 0.0487 - val_mae: 0.1472
Epoch 7/10
112/112 [==============================] - 102s 906ms/step - loss: 0.1430 - mse: 0.0409 - mae: 0.1430 - val_loss: 0.1410 - val_mse: 0.0411 - val_mae: 0.1410
Epoch 8/10
112/112 [==============================] - 102s 908ms/step - loss: 0.1437 - mse: 0.0408 - mae: 0.1437 - val_loss: 0.1427 - val_mse: 0.0437 - val_mae: 0.1427
Epoch 9/10
112/112 [==============================] - 102s 909ms/step - loss: 0.1413 - mse: 0.0393 - mae: 0.1413 - val_loss: 0.1415 - val_mse: 0.0387 - val_mae: 0.1415
Epoch 10/10
112/112 [==============================] - 102s 910ms/step - loss: 0.1406 - mse: 0.0383 - mae: 0.1406 - val_loss: 0.1430 - val_mse: 0.0399 - val_mae: 0.1430
06-11 22:21:04, INFO     Done training!
06-11 22:21:04, INFO     Start predicting subtomograms!
06-11 22:22:53, INFO     Done predicting subtomograms!
06-11 22:22:53, INFO     Done Iteration1!
06-11 22:22:53, INFO     Start Iteration2!
</div></code></pre>
<p>You can also continue from the pretrained model for this dataset
provided in the link. The following command will use the pre-trained
network model as the model of 1st iteration, then predict subtomos and
train networks starting from this model.:</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --pretrained_model ./pretrained_model.h5  --gpuID 0,1,2,3 
</div></code></pre>
<p>Another option is to continues from previous runs, with
<strong>continue_from</strong> command. This option allows reading the parameter from
previous iteration in '.json' file and continuing from that. For example:</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --continue_from results/refine_iter20.json  --gpuID 0,1,2,3 
</div></code></pre>
<h4 id="216-predict">2.1.6 Predict</h4>
<p>During the refinement step, the network models are saved in <strong>result_dir</strong>
folder. You can select one and apply it to your entire tomograms in the
tomogram star file. For example:</p>
<pre><code>isonet.py predict tomograms.star ./results/model_iter40.h5 --gpuID 0,1,2,3
</code></pre>
<p>This process may take a few minutes to predict all tomograms in the
tutorial dataset. You can also use <strong>tomo_idx</strong> to tell the program which tomogram(s) you want to predict.</p>
<p>Now, We now the missing wedge corrected tomograms in the corrected_tomos folder.</p>
<h3 id="22-isonet-for-cellular-tomography">2.2 IsoNet for Cellular tomography</h3>
<p><a href="./Example1.md">Here</a> missing wedege correction and denoising for a tomogram of a neuronal synapse. This synapse dataset is a acquired with volta phase plate, thus CTF deconvolution step is not performed.</p>
<p align="center"><img src="figures/pp676_demo.png" alt="pp676_demo" width="600" /> </p>
<p>This example processes tomogram of <strong>synapse structure</strong> through <strong>IsoNet</strong>.</p>
<h4 id="221-run-isonet-from-command-line">2.2.1 Run IsoNet from command line</h4>
<p>Prepare working directory like following; Data used for demonstration can be found here</p>
<pre class="hljs"><code><div>isonet_demo/
└── tomofile
    └── pp676-bin4-5i-demo.rec
</div></code></pre>
<ol>
<li>Prepare STAR file</li>
</ol>
<p>command line:</p>
<pre class="hljs"><code><div>isonet.py prepare_star tomofile/ --pixel_size 18.12 --number_subtomos 300
</div></code></pre>
<p>The default file name of STAR file will <em>tomograms.star</em> ; Contents in this file can be modified through text editors.</p>
<ol start="2">
<li>Deconvolution</li>
</ol>
<p>This step is not necessary for tomograms acquired with a phase plate.</p>
<ol start="3">
<li>Generate mask</li>
</ol>
<p>To exclude the areas that are devoid of sample, we apply a binary sampling mask to each tomogram. This step will improve the quality of the training dataset. Since this demo tomogram has a bin-factor of 4, a smaller Gaussian filter can smooth out noise and keep the fine structure. We set <em>patch_size</em> to 2. Usually, the top and bottom (along the z-axis) regions are lack of content. We mask out the top 15% and bottom 15% region by setting <em>z_crop</em> to 0.15.</p>
<pre class="hljs"><code><div>isonet.py make_mask tomograms.star --z_crop 0.15 --patch_size 2
</div></code></pre>
<p>The output mask will be placed in the <strong>mask</strong> by default.</p>
<ol start="4">
<li>Extract subtomogram</li>
</ol>
<p>This step extracts small volumes (here we also call subtomograms) from big tomograms, with the sampling mask generated in the previous step.</p>
<pre class="hljs"><code><div>isonet.py extract tomograms.star
</div></code></pre>
<p>The default subtomogram folder is <strong>subtomo</strong>. And <strong>subtomo.star</strong> file is the corresponding STAR file of subtomograms.</p>
<p>Up to this step, our workspace is like this:</p>
<pre class="hljs"><code><div>isonet_demo/
├── mask
│   └── pp676-bin4-5i-demo_mask.mrc
├── subtomo
│   ├── pp676-bin4-5i-demo_000000.mrc
│   ├── pp676-bin4-5i-demo_000001.mrc
│   ├── pp676-bin4-5i-demo_000002.mrc
│   ├── pp676-bin4-5i-demo_000003.mrc
		.
		.
		.
│   ├── pp676-bin4-5i-demo_000298.mrc
│   └── pp676-bin4-5i-demo_000299.mrc
├── subtomo.star
├── tomofile
│   └── pp676-bin4-5i-demo.rec
└── tomograms.star
</div></code></pre>
<ol start="5">
<li>Refine</li>
</ol>
<p>This process iteratively fills the missing wedge information by training deep neural networks with subtomograms. The default refinement parameters are great for most cellular tomograms. Here, we only set the ID of GPU and the results directory name where the neural network models are saved during iterative refinement.</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --gpuID 0,1 --result_dir demo_results
</div></code></pre>
<p>The training time depends on the GPU performance. This example takes <strong>7 hours</strong> on two Nvidia gtx1080 cards for 25 iterations.</p>
<ol start="6">
<li>Predict</li>
</ol>
<p>All trained neural-net models after each iteration are stored in the results directory (<strong>demo_results</strong> in this example ). Predict will employ one of these models (typically, those models after 25-30 iterations, corresponding to denoise levels between 0.15-0.20) to do missing wedge correction to the original tomogram (pp676-bin4-5i-demo_mask.mrc). In this demonstration, we use the model after 25 iterations.</p>
<pre class="hljs"><code><div>isonet.py predict tomograms.star demo_results/model_iter25.h5 --gpuID 0,1
</div></code></pre>
<p>The prediction time consumption is much less than the refinement step. This tomogram will take less than <strong>2 minutes</strong> to predict using two Nvidia gtx1080 cards.</p>
<h4 id="222-run-isonet-with-gui">2.2.2 Run IsoNet with GUI</h4>
<p>Open a terminal window, type the following to launch the GUI</p>
<pre class="hljs"><code><div>isonet.py gui &amp;
</div></code></pre>
<img src="./figures/gui1.png" alt="image-20220207001846094" style="zoom:30%;" />
<ol>
<li>Add tomograms</li>
</ol>
<p>Click <em>insert</em> on the upper-right panel and then click <em>None</em> in the <em>MicrographName</em> column, select one tomogram.</p>
<img src="./figures/gui_addtomo.png" alt="image-20220207002107926" style="zoom:30%;" />
<p>Set the pixel size and the number of subtomogram to be extracted from this tomogram.</p>
<img src="./figures/gui_settomo.png" alt="image-20220207002456475" style="zoom:33%;" />
<ol start="2">
<li>Generate mask</li>
</ol>
<p>Set proper parameters for producing mask.</p>
<img src="./figures/gui_genmask.png" alt="image-20220207002807345" style="zoom:33%;" />
<p>And click <strong>Generate Mask</strong> button.</p>
<img src="./figures/gui_clickmask.png" alt="image-20220207002915179" style="zoom:33%;" />
<p>We can view the produced mask via 3dmod: Click the small index  '1'  at the beginning of the row in the tomogram table and click <strong>3dmod view</strong></p>
<img src="figures/gui_viewmask.png" alt="image-20220207003308839" style="zoom:33%;" />
<p>Check the mask you generate and adjust the parameter if necessary.</p>
<ol start="3">
<li>Extract subtomogram</li>
</ol>
<p>Click <strong>Extract</strong></p>
<img src="figures/gui_clickextract.png" alt="image-20220207002915179" style="zoom:33%;" />
<ol start="4">
<li>Refinement</li>
</ol>
<p>Click the <strong>Refinement</strong> tab at the uppermost panel and set the GPU ID and results folder name.</p>
<img src="figures/gui_refinetab.png" alt="image-20220207003550613" style="zoom:33%;" />
<p>Click <strong>Refine</strong> button below to start iterative refinement.</p>
<img src="figures/gui_clickrefine.png" alt="image-20220207003812744" style="zoom:33%;" />
<p>If you want to run the refinement step on a remote machine or cluster using command-line, you can check the 'only print command ' box. Then when you click <strong>Refine</strong> button, the command for refinement will output to your terminal window.</p>
<ol start="5">
<li>Predict</li>
</ol>
<p>Click the <strong>Prediction</strong> tab at the uppermost panel.</p>
<img src="figures/gui_predick.png" alt="image-20220314193414624" style="zoom:33%;" />
<p>Specify the GPU and choose the model for prediction. Click <strong>Predict</strong> to star predicting.</p>
<p>You can view the missing wedge corrected tomogram by clicking <strong>3dmod</strong>.</p>
<h2 id="3-individual-tasks">3 Individual tasks</h2>
<p>This chapter is a detailed description of each command. Among those commands, refine and predict are computational extensive and require GPU acceleration.</p>
<h3 id="31-prepare-tomograms-and-star-file">3.1 Prepare tomograms and STAR file</h3>
<p>IsoNet uses star file format to store information of tomograms. This file can be prepared using <strong>isonet.py prepare_star</strong> command prior to subsequent processing. To do so, users should prepare a folder containing all tomograms.
Binning the tomograms to pixel size of more than 10 A is recommended since the target z-axis resolution should be about
30A. Too large (&gt;25A) or too small (&lt;5A) pixels might reduce the efficiency of IsoNet network training. The default <strong>pixel_size</strong> parameter is 10A. We typically use a folder containing 1 to 5 tomograms as input.</p>
<p>  Input tomograms can be either reconstructed by SIRT or WBP algorithm. The tilt axis should be y-axis and recommended tilt range is from -60 to 60 degrees, without x-axis tilt, while other tilt ranges might also work. The tilt series can be collected with any tilt schemes, continuous, bidirectional or dose-symmetric.</p>
<p> If you do not want to perform CTF deconvolution, especially when the tomogram is acquired by phase plate or the tomogram is already CTF corrected, the <strong>defocus</strong> for that tomogram in star file can be left as 0. Otherwise, you can use the <strong>defocus</strong> parameter to set one defocus value for the tomograms. This value should be the defocus value of the zero tilt image. We do not consider defocus variation across different tilted images in this version of IsoNet, since IsoNet is not optimized for high-resolution reconstruction currently.</p>
<p>  When you have multiple tomograms in the folder, the <strong>defocus</strong> parameter (in angstrom) for each tomogram should be adjusted in the star file with your text editor (or in IsoNet GUI), after the tomogram star file has been generated with <strong>isonet.py prepare_star</strong> command.</p>
<h3 id="32-ctf-deconvolve">3.2 CTF deconvolve</h3>
<p>Given the defocus values in the tomogram star file, CTF deconvolution can be performed by applying a Weiner filter to each tomogram. This step is similar to the CTF deconvolve in the software Warp. It not only reduces the CTF artifact but also enhances the low-resolution signal to train the network more easily. This step can be skipped for tomograms acquired with a phase plate.</p>
<p>Two parameters, <strong>snrfalloff</strong> and <strong>deconvstrength</strong>, are worthy to be tuned in this step to enhance visual contrast of the tomograms. If these parameters are not set in the command, the values in the <em>star</em> file will be used; If the star file does not contain these parameters, default 1.0 will be used for both parameters.
  The effect of these two parameters is shown in the following figures. You can also specify <strong>tomo_index</strong> (e.g. 1,3-4 ) so that only the specific tomogram or tomograms will be processed. Another parameter <strong>hipassnyquest</strong> applies a high pass filter at very low frequency, changing this
parameter might be helpful if the tomograms become too blurry.</p>
<p align="center"><img src="figures/snrfalloff.png" width="800" /> </p>
<p style="text-align: center; font-size: 11pt"> 2D slices of CTF deconvolved tomograms with different deconvstrength parameters. 
			Left: deconvstrength=0.5; middle: deconvstrength=1;right:deconvstrength=1.5 </p>
<p align="center"> <img src="figures/decovstrength.png" width="800"> </p>
<p style="text-align: center; font-size: 11pt"> 2D slices of CTF deconvolved tomograms with different snrfalloff parameters. Left: snrfalloff=0.5; middle: snrfalloff=1;right:snrfalloff=1.5
<p>Multiple CPUs can be used for CTF deconvolution, the number of CPUs is given by the parameter <strong>ncpu</strong>, with a default value of 4.</p>
<p>When your computer has enough memory, keep <strong>chunk_size</strong> None. Otherwise, You can let the IsoNet program crop the tomogram into multiple chunks for multiprocessing and assemble them into one. The <strong>chunk_size</strong> defines the size of an individual chunk. This option may induce artifacts along the edges of chunks. When that happens, you may try a larger <strong>overlap_rate</strong>.</p>
<h3 id="33-generate-mask">3.3 Generate mask</h3>
<p>To obtain a training dataset, sub-tomograms are randomly extracted from tomograms. However, when the sample in a given tomogram is sparsely distributed, most of the extracted sub-tomograms will not contain meaningful information. Therefore, the performance of network training might be reduced, although in most cases, you can still get a reasonable
result from training without masks.</p>
<p>To help with getting a more meaningful training dataset, we introduce the
<strong>make_mask</strong> module, which created three types of mask:</p>
<ol>
<li>Pixel intensity mask</li>
<li>Standard deviation mask</li>
<li>User defined polygon mask</li>
</ol>
<p>The final mask created by the command is the <strong>intersection</strong> of these three types of masks.</p>
<h4 id="331-pixel-intensity-mask">3.3.1 Pixel intensity mask</h4>
<p>This type of mask will mask out empty areas that have relatively low local poxel density. It will first suppress noise with a 3D Gaussian filter and then apply a 3D sliding window maximum-density filter to the tomograms. The window size of the maximum filter is defined by <strong>patch_size</strong> parameter. This size can be increased if the tomograms are too noisy.</p>
<p>In this filter tomogram, the areas with relatively smaller density values will be deemed as empty space and can be excluded with parameter <strong>density_percentage</strong>, ranging from 0 to 100, meaning the only include this percentage of pixels in the mask.</p>
<p>Usually, a lower <strong>density_percentage</strong> value should be used when tomograms have sparsely distributed samples. This type of mask does not work well when the tomograms do not have uniform backgrounds, e.g. darker on one side of the tomogram. When you don't want to use this mask, set the <strong>density_percentage</strong> value to 100.</p>
<h4 id="332-standard-deviation-mask">3.3.2 Standard deviation mask</h4>
<p>Recognizing that the &quot;empty&quot; regions of the tomograms are often areas with low standard deviation (STD), this standard deviation mask is designed to exclude the low STD areas.</p>
<p>To do so, we calculated the STD of a volume centered at the evaluating pixel (local STD). The size of the volume to measure local STD is defined by the parameter <strong>patch_size</strong>, this parameter is also used to define the size of max filter in pixel intensity mask.</p>
<p>Pixels with STD ratio larger than the <strong>std_percentage</strong>% of all pixels will be included in the mask. When you don't want to use this mask, set the <strong>std_percentage</strong> value to 100.</p>
<p align="center"> <img src="figures/mask.png" width=1000 > </p>
<p style="text-align: center; font-size: 11pt">XY slices of tomograms and corresponding masks. Both using density_percentile=50 and std_percentile=50 </p>
<h4 id="333-draw-a-polygon-to-define-area-of-interest">3.3.3 Draw a polygon to define area of interest</h4>
<p>This option is new in version 0.2. The polygon should be drawn in 3dmod (a command in IMOD). The polygon file (with extension .mod) corresponds to the <strong>MaskBoundary</strong> parameter in star file, or the table in graphic user interaface (GUI). This option is espacially useful to find carbon areas that can not detecte with the above two types of masks.</p>
<p>To generate polygon mask in GUI, first click <strong>3dmod view</strong> to open a tomogram file.</p>
<p>Select <strong>model</strong> mode in the 3dmod window. Then click few points on tomograms to make a polygon (This mouse buttom assignment can be set in 3dmod perference).</p>
<p align="center"> <img src="figures/polygon_mask_3dmod.png" width=800 > </p>
<p style="text-align: center; font-size: 11pt">Draw polygon with 3dmod </p>
<p>Optionaly, after you created a polygon, you can click one point on the top and bottom slices each to define z range of the mask.</p>
<p>Then save the polygon to a file (with .mod extension) and double click the corresponding field of MaskBoundary in the GUI table to load the imod model file. Then execute <strong>make mask</strong> button, the generated mask will exclude areas outside polygon.</p>
<p align="center"> <img src="figures/polygon_mask_chooseMask_boundary.png" width=800 > </p>
<p style="text-align: center; font-size: 11pt">Double clock the selected field and load the imod model file </p>
<p align="center"> <img src="figures/polygon_mask_final.png" width=800 > </p>
<p style="text-align: center; font-size: 11pt">Mask generated with user defined polygon </p>
<p>Note: To create mask boundary with command line and <strong>without</strong> GUI. You should modify mask boundary column in the tomogram star file, then run <strong>isonet.py make_mask tomograms.star</strong>. The modified star file should look like follows:</p>
<pre class="hljs"><code><div>data_

loop_
_rlnIndex #1
_rlnMicrographName #2
_rlnPixelSize #3
_rlnDefocus #4
_rlnNumberSubtomo #5
_rlnSnrFalloff #6
_rlnDeconvStrength #7
_rlnDeconvTomoName #8
_rlnMaskBoundary #9
_rlnMaskDensityPercentage #10
_rlnMaskStdPercentage #11
1       ./tomograms/TS01-wbp.rec        10.880000       38838.000000    100     1.000000        1.000000        ./deconv/TS01-wbp.rec   ./tomograms/TS01-wbp.mod        50.000000       50.000000 
</div></code></pre>
<p>If you want only define z range instead of making polyson. you can simply click two points on the tomograms to define z range. Or specify the <strong>z_crop</strong> parameter. For example, <strong>--z_crop 0.2</strong> will mask out both the top 20% and bottom 20% region along the z-axis.</p>
<h3 id="34-extract">3.4. Extract</h3>
<h4 id="341-extract-from-tomograms">3.4.1 Extract from tomograms</h4>
<p>This step randomly extracts the subtomograms from tomograms listed in the input tomogram star file. The output of this command is a folder containing all the subtomograms and a star file containing the information of those subtomograms.</p>
<p>The number of subtomograms to be extracted for each tomogram should be written in the tomogram star file in the column of (_rlnNumberSubtomo). Users can modify this number in the star file. Ideally, the smaller the masked area, the smaller this number should be. Usually total 300 subtomograms are sufficient for IsoNet refine.</p>
<p>If mask files are provided in the input tomogram star file, the centers of the subtomograms are always inside the mask regions. If CTF deconvoluted tomograms are provided in the tomogram file, those
tomograms will be used for the subtomogram extraction unless the
<strong>use_deconv_tomo</strong> parameter is set to False.</p>
<p>The parameter <strong>cube_size</strong> is the size of the cubic volume for
training, not the size of extracted subtomograms. The actual size of the extracted subtomograms, which is defined as <strong>crop_size</strong>, is by default 16 + cube_size. The <strong>cube_size</strong> should be divisible by 8 and is usually limited by the GPU memory. 64 or 96 is often a good estimation for <strong>cube_size</strong>. If you encountered
an out-of-memory (OOM) problem during network training, reducing this value is one of the choices.</p>
<h4 id="342-prepare-star-file-from-subtomograms">3.4.2 Prepare <em>star</em> file from subtomograms</h4>
<p>This step is not in the main workflow of IsoNet, but might be helpful if you already have subtomograms extracted through other softwares. For example, if you are only interested in processing subtomograms of a particular protein, you can manually pick and extract them, then prepare star file with this command. We also recommend these subtomograms are downing-scaled to &gt;10 A/pixel and CTF deconvoluted if those are not acquired with phase plate.</p>
<p>This step generates a <em>star</em> file from a folder containing only subtomogram files. The subtomogram files should be in mrc format, with extension of &quot;.mrc&quot;. The generated star file can be used as input for refine.</p>
<p>This command works as follows, where &quot;folder_name&quot; is the folder containing subtomograms:</p>
<pre class="hljs"><code><div>isonet.py prepare_subtomo_star folder_name [--output_star] [--cube_size] 
</div></code></pre>
<p>The default output star file is <strong>subtomo.star</strong>. <strong>cube_size</strong> is the size of the cubic volumes used for training. This value should be smaller than the size of subtomograms and should be divisible by 8, eg. 64, 96. If this value isn't set, <strong>cube_size</strong> is automatically determined as int(subtomo_size / 1.5 + 1)//16 * 16</p>
<h3 id="35-refine">3.5 Refine</h3>
<p>This process iteratively trains neural networks to fill the missing
wedge information using the same tomograms whose missing wedge artifacts were added to other directions. The denoising module can also be enabled in this step, making the network capable of both reducing noise and Recovering missing wedge. After refine, the neural network model in each iteration are saved in the results folder. The network models with suffix of &quot;.h5&quot; can be used for the prediction step.</p>
<h4 id="351-computation-resources">3.5.1 Computation resources</h4>
<p>At the beginning of each iteration, IsoNet will process the
subtomograms, such as rotating, cropping, and applying missing wedge filter. Only CPUs are used for those processes. The parameter
<strong>preprocessing_ncpus</strong> is used to define how many CPU cores are used for this preparation step.</p>
<p>Users have to specify <strong>gpuID</strong>, e.g. 0,1,2,3, for the network training, so that 3D volumes will be distributed across those GPUs. Information of available GPUs can be found through the command: <em>nvidia-smi</em>. In general, using more GPUs reduces GPU memory requirement for each GPU and current network training can not be performed across multiple computer machines.</p>
<p>The <strong>data_dir</strong> is the folder that temporally stores the training
and test data pairs. The files in that folder will be updated every
iteration. Setting it to a faster drive such as SSD or memory file
system will presumably increase the speed of network training, though not fully bench-marked on the developer's side.</p>
<h4 id="352-optimizing-training-speed">3.5.2 Optimizing training speed</h4>
<p>One <strong>iteration</strong> of refinement contains three steps: training data
preparation, network training, and subtomogram prediction. The model will be refined iteratively based on previous prediction results. In practice, a total of 10 to 20 iterations is typically used for refinement without denoising. Please refer to the denoising section for more details.</p>
<p>The training step is divided into several <strong>epochs</strong>. Each epoch will traverse through the randomly shuffled data set. The default value(10) for the number of epochs is usually sufficient. Training data pairs are grouped into batches to feed into each epoch. The <strong>batch_size</strong> should be divisible by the number of GPUs so that the data can be distributed into multiple GPUs. If you are using multiple GPUs and <strong>batch_size</strong> is not set, the default value is two times the number of GPUs. If you are using a single GPU, the default <strong>batch_size</strong> is four. We tested <strong>batch_size</strong> of 4-12 can result in a good performance, too large <strong>batch_size</strong> might lead to out of memory (OOM) error. <strong>steps_per_epoch</strong> defines how many batches are to be processed in one epoch. A value between 100 to 300 are recommended. If this value is not set by the user, the default <strong>steps_per_epoch</strong> is min(number_of_subtomograms * 6 / batch_size , 200)</p>
<h4 id="353-denoising">3.5.3 Denoising</h4>
<p>The <strong>noise_start_iter</strong> parameter defines when denoising will be applied during the refine.</p>
<p>Usually, this parameter is set to be the iteration in which undenoised training converged.</p>
<p>The <strong>noise_level</strong> is the ratio of the standard deviation of the additive noise compare to that of the original
data. Once the denoise was applied, the mean absolute error loss of the training will be increased.</p>
<p>If the <strong>noise_level</strong> is too high, the training might fail, as indicated by the extremely large losses.</p>
<p>You can set both <strong>noise_start_iter</strong> and <strong>noise_level</strong> with multiple
values. So that you can gradually increase the <strong>noise_level</strong> during
the training.</p>
<p>For example, in the following command, the <strong>iteration</strong> parameter is
set to 30, <strong>noise_level</strong> is set to 0.1,0.2, and <strong>noise_start_iter</strong>
is 11,21. Then the first 10 iterations are trained without denoising,
11-20 iterations are trained with noise level 0.1, 21-30 iterations are
trained with noise level 0.2. You can use the neural network model from
iteration 10, 20, 30 to predict the same tomogram and distinguish which
level of denoising is best for your tomograms.</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --iter 30 --noise_level 0.1,0.2 --noise_start_iter 11,21
</div></code></pre>
<h4 id="354-network-structure">3.5.4 Network structure</h4>
<p>IsoNet allows users to modify the network structures by the input arguments. For example, it might be useful to increase or decrease the
size of the network by increasing or decreasing <strong>unet_depth</strong>, though this is
not recommended unless users want to test the performance of
different networks.</p>
<p>Another parameter that decides the complexity of the neural network is <strong>filter_base</strong>. It determines the scale of the number of feature channels and has been set to 64 by defaults. Increasing it could lead to a better result at the cost of a longer training time. Please note that parameters defining network structure will be ignored when using <strong>pretrained_model</strong> of <strong>continue_from</strong>.</p>
<p>If <strong>normalize_percentile</strong> is set True, tomograms will be normalized by
percentile, which scales the sub-tomograms in a range approximately from
0 to 1. If this is set False, the sub-tomograms will be normalized to
have a mean of zero and a standard deviation of 1.</p>
<h4 id="355-continuing-using-the-previously-trained-network">3.5.5 Continuing using the previously trained network</h4>
<p>If you want to continue with a model from previous iterations of refine,
you can specify the <strong>continue_from</strong> argument, which takes the '.json'
file that is generated at each iteration.</p>
<p>For example:</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --continue_from ./results/refine_iter30.json --gpuID 0,1,2,3 --iterations 50 
</div></code></pre>
<p>If you already have a trained network model (with a file extension of
.h5), instead of '.json' file , you may want to choose
<strong>pretrained_model</strong> option:</p>
<p>For example:</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --pretrained_model ./pretrained_model.h5 --gpuID 0,1,2,3 
</div></code></pre>
<p>This command enables using your pretrained model to predict the
subtomograms of the first iteration. Starting with the second iteration,
you are refining this model using the subtomograms in the subtomo.star</p>
<h3 id="36-predict">3.6 Predict</h3>
<p>This module applies the trained network model to tomograms to restore
the information in the missing wedge region of tomograms. It takes the
tomogram star file, which can be generated with <strong>isonet.py prepare_star</strong> command, and a trained network model (with .h5 file
extension) as input. The input tomograms in the tomogram star file are
typically the exact tomograms used for training or other tomograms with
similar sample and imaging conditions. If the network is trained with
CTF deconvolved tomograms, the tomograms used for predict should also be
CTF deconvolved.</p>
<p>This step is much faster than refine step. <strong>gpuID</strong> defines which
GPU(s) will be used for predicting, e.g. 0,1,2,3. If this parameter is
not set, CPU will be used for prediction, which could take much longer
time than using GPU.</p>
<p>To fit the tomogram into the GPU memory, one tomogram is divided into
multiple tiles for the missing wedge correction and the overlap
tile strategy is used to prevent the artifact during montaging the tiles. To
implement this strategy, the <strong>crop_size</strong> should be larger than the
<strong>cube_size</strong>. The <strong>cube_size</strong> and <strong>crop_size</strong> are suggested to be
consistent with the training settings. If <strong>crop_size</strong> is not large
enough, you may observe artifacts of grids between the adjacent tiles.</p>
<p>The <strong>batch_size</strong> defines the number of subtomograms grouped
together for network predicting, this value should be divisible by the
number of GPU. Larger <strong>batch_size</strong> will save more predicting time but
occupy larger your GPU memory. <strong>normalize_percentile</strong> should be the
same as that parameter in refine.</p>
<pre class="hljs"><code><div>isonet.py predict tomogram.star path_to_network_model --gpuID 0,1,2,3 --cube_size 80 --crop_size 128
</div></code></pre>
<h2 id="4-gui">4 GUI</h2>
<p>This section briefly described IsoNet graphic user interface (GUI). You
can watch our <a href="https://drive.google.com/drive/folders/1DXjIsz6-EiQm7mBMuMHHwdZErZ_bXAgp">tutorial video</a> for the details on how to use GUI.</p>
<p>The GUI can be started by the following command:</p>
<pre class="hljs"><code><div>isonet.py gui
</div></code></pre>
<img src="figures/gui_1.png" width="600">
<p>This software mainly have 3 pages, they are <strong>Preparation</strong>,
<strong>Refinement</strong> and <strong>Prediction</strong>.</p>
<ol>
<li>
<p>Preparation includes the preprocessing steps to prepare the dataset to
be trained in the later Refinement step.</p>
<ul>
<li>
<p>Deconvolve CTF: Correct CTF and increase the contrast of tomograms.</p>
</li>
<li>
<p>Generate mask: create mask to define the region of interest in the tomograms</p>
</li>
<li>
<p>Subtomograms extraction: generate the training dataset</p>
</li>
</ul>
</li>
<li>
<p>Refinement trains a neural network to correct the missing-wedge.</p>
</li>
<li>
<p>Prediction generates corrected tomograms based on the trained model from the Refinement step.</p>
</li>
</ol>
<p>The GUI will automatically read the <strong>tomograms.star</strong> as default if it exists in the current folder.</p>
<p>In the preparation tab, an input table allows users to create or load <strong>.star</strong> file. You can click insert to add a new row into the table. For
tutorial dataset, you need to specify MicrographName
(reconstructed tomogram), pixel size, estimated defocus value for the tomogram's 0 degree image. You can select an entire row by clicking the index of the row on
the left-most region. After being selected, you can duplicate it or delete it
by clicking the insert or Delete button on the right. '3dmod view' helps
users to visualize selected tomograms and/or masks.</p>
<p>Further operations of IsoNet GUI are intuitive. Please refer to the <a href="https://drive.google.com/drive/folders/1DXjIsz6-EiQm7mBMuMHHwdZErZ_bXAgp">video tutorial</a> or the <a href="Example1.md">first example</a>.</p>

</body>
</html>
